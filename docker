Basic Docker Commands:
* Docker run <image name> 	
 ->  To run a container and it will pull the image
* Docker ps 	
->  To list all running containers
* Docker ps   -a	
->  To list all running and stopped containers
* Docker stop <container name or ID > 	
-> To stop a running container
* Docker rm <container name or ID> 	
-> To remove stopped or exited container permanently.
* Docker rm <con1>  < con2>
* Docker images 	
->  To see the list of images we have 
* Docker rmi <image name or id > 	
-> To delete an image and we need to ensure that all containers are stopped.
* Docker pull <image name> 
		-> to download the image
* Docker run Ubuntu
* Docker run Ubuntu sleep 5
* Docker run <image name> 	
-> It will run a container in attached mode. ( All the running process will be showing) Press ctrl+c to quit from that (by pressing ctrl +c that container will stop automatically)

* Docker run -d <image name> 	
-> This will run the container in detached mode (In background)

* Docker attach <container name or ID) 
->  It is used to attach back to the container which is running in detached mode

* Docker run – it <image name> 
-> It is used to open an interactive session within that container 

* Docker run - - name <my-container name> < image name or id>  
* docker run --name=<my-container-name> <image name or id>
-> It is used to create a container  with specified name

*Docker run <Image name : version>
-> To run a container on specified version, If you don’t specify default tag will be latest.s

* docker run -p <host-port>:<container-port> <image-name>
-> you can map ports between the container and the host.

* docker run -v <host-path>:<container-path> <image-name>
Docker run  -v /opt/datadir:/var/lib/mysql  mysql
-> suppose if you created a MySql container and stored some data. Accidentally or intentionally that container was stopped and deleted. So the data will be gone. So if we store the data outside container then that data will be safe. To store the data outside container we use volumes.

* docker inspect <container name or ID> 
-> To see the more details of container in json format.

*  docker logs <container-id or container-name>
-> used to display the logs generated by a running or stopped container	

* docker run Ubuntu cat /etc/*release*
-> it will run a container on Ubuntu and shows the release version of Ubuntu

* docker run -q
-> It will give the lsit of id's of running containers

* docker run -p <host port> : <container port> <image name>

Docker Image
-------------->

docker build Dockerfile -t <my image name>    ----- -t for providing tag
docker build -t <my image name> .             
docker build -t <my image name> -f <custom Docker file> .             ----If your Dockerfile is named differently, you can specify it explicitly with the -f option

<< this commands are used to create a image>>

docker push <my image name> 
-> used to push the image to docker hub

docker history <image name>
->  command allows you to view the history of an image, showing each layer and its associated commands.

docker build -t your-dockerhub-username/your-image-name:your-tag .
docker login
docker push your-dockerhub-username/your-image-name:your-tag


docker run -e < env variable= value> <image name>
-> THis command is used to pass values when running a container. Because every time we can't change the code

docker inspect <container id or name>
-> this is used to know the environment variables set to the container. Under the config section we can see the Env variables.


docker run ubuntu <command>
ex) docker run ubuntu sleep 5

-> In this providing command is optional. So if we don't provide sleep process don't run.
to make this permanent we need to give command in docker file. so that if will always run when a container is started.
ex) FROM Ubuntu
    CMD sleep 5

In providing CMD there are 2 ways
1) CMD command param1
2) CMD ["command", "param1"]  (correct) -- this is json array format
   CMD ["sleep5"] (wrong)
when using 2nd format --- the first element in the array should be executable

what if I wanted to change the no.of seconds is sleeps?

-> we can write {docker run ubuntu sleep 10} but this not good to see

so, we can use entrypoint
ex) FROM Ubuntu
    ENTRYPOINT ["sleep"]
now we can give {docker run ubuntu 10}
 we can give only {docker run ubuntu} but it will sleep for some time

ex) FROM ubuntu
    ENTRYPOINT ["sleep"]
    CMD ["5"]
if we give {docker run ubuntu 10} then 5 will be override by 10.

docker run --entrypoint sleeper2.0 ubuntu 10
-> this will change the entrypoint name (ex- sleep to sleeper2.0)

Docker Compose
--------------->
If we need to set up a complex application running multiple services, better way to do it is to use docker compose.
With docker compose we could create a configuration file in YAML format called docker-compose.yml

* docker-compose up
->  command is used to start services defined in a Docker Compose YAML file.


Example :
we are taking a sample application - voting appliacation
 ~ this provides an interface for a user to vote and another interface to show the results.

Voting app - pyhton  (we will vote here)
in memory db - redis   (that will come to memory datadase here redis)
worker - . net		(from redis will come to worker to process the vote count)
db - postgresql		( then it will store to postgreSQL)
result-app - node js	( then it will display the result)

* we need to prepare the images first (redis, postgre are offical images) (voting-app, result-app, worker are images created by us)
firstway ]]]
docker run -d --name=redis redis
docker run -d --name=db postgres
docker run --name=vote -p 5000:80 voting-app
docker run --name=result -p 5001:80 result-app
docker run -d --name=worker worker


After running all container if we try to access vote container it is getting error because we didn't them each other,  like vote to redis....
To solve this we use links --> links is used to link two containers

--link container2:alias name

docker run -d --name=redis redis
docker run -d --name=db postgres
docker run --name=vote -p 5000:80 --link redis:redis voting-app
docker run --name=result -p 5001:80 --link db:db result-app
docker run -d --name=worker --link db:db --link redis:redis worker

(version1) - In v1 docker compose attaches all the containers it runs to the default bridged network and then use links to enable communication
docker-compose.yml

redis:
	image: redis
db:
	image: postgre:9.4
vote:
	image: voting-app      build: ./vote (if images are no created iy yet, vote, result, woker here are folder that contains code)
	ports:
		-5000:80
	links:
		-redis
result:
	image: result-app	build: ./result
	ports:
		-5001:80
	links:
		-db
worker:
	image: worker		build: ./worker
	links:
		-redis
		-db



(version2) - In this version docker compose automatically creates a dedicated bridge network for this application and then attaches all containers to that new network.
all containers then able to communicate to each other using each other's service name. no need to use links in v2.

docker-compose.yml

version: "2"
services:
	redis:
		image: redis
	db:
		image: postgre:9.4

	vote:
		image: voting-app
		ports:
			-5000:80
		depends_on:
			- redis
	result:
		image: result-app
		ports:
			-5001:80
		depends_on: 
			-db
	worker:
		image: worker	
		depends_on:
			-redis
			-db


version3 - this v3 supports for docker swarm  (later we will know more)


version: "3"
services:
	redis:
		image: redis
		networks:
			-back-end
	db:
		image: postgre:9.4
		environment:
			POSTGRES_USER: postgres     (IN LATEST VERSION FOR POSTGRES WE NEED TO GIVE USER AND PASSWORD COMPULSORY)
			POSTGRES_PASSWORD: postgres
		networks:
			-back-end		
	vote:
		image: voting-app
		ports:
			-5000:80
		depends_on:
			- redis
		networks:
			-front-end
			-back-end
	result:
		image: result-app
		ports:
			-5001:80
		depends_on: 
			-db
		networks:
			-front-end
			-back-end
	worker:
		image: worker	
		depends_on:
			-redis
			-db
		networks:
			-back-end
networks:
	front-end
	back-end




Python Application:Dockerfile

FROM python
COPY . /app
WORKDIR . /app
RUN apt-get update && apt-get install -y python
RUN pip install -r requirements.txt
EXPOSE 5000
CMD ['python', 'app.py]


DOCKER ENGINE::
When we install docker on a linux host, you're actually installing three different competencies

Docker CLI
REST API
Docker Deamon 

form different laptop, using docker CLI we can connect to docker deamon in using command 

docker -H=HOST:PORT run IMAGE NAME
docker -H=10.123.2.1:2375 run nginx

So, when you run this command, it tells Docker to connect to a remote Docker daemon at the specified address (10.123.2.1:2375) and then run a new container based on the Nginx image. 

There is no restriction as to how much of a resource.... a container can use. So there is a chance of utilizing all resources on the underlying hosts

* docker run --cpus=.5 ubuntu
-> when you run this command, Docker will create and start a new container based on the Ubuntu image, and the container will be limited to using a maximum of 50% of a CPU core.

* docker run --memory=100m ubuntu
-> Docker will create and start a new container based on the Ubuntu image, and the container will be limited to using a maximum of 100 megabytes of memory.

